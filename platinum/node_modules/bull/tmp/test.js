var Queue = require('../');
var s3 = require('s3');
var awsQueue = Queue('S3 Queue');

var debug = console.log

var concurrency = 1;

var client = s3.createClient({
    maxAsyncS3: 20, // this is the default
    s3RetryCount: 0, // this is the default
    s3RetryDelay: 0, // this is the default
    multipartUploadThreshold: 20971520, // this is the default (20 MB)
    multipartUploadSize: 15728640, // this is the default (15 MB)
    s3Options: {
        accessKeyId: 'AKIAJED7HWTBPBKW5RTQ',
        secretAccessKey: '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',
        //     endpoint: config.get('App.aws.s3.endPoint')
        // any other options are passed to new AWS.S3()
        // See: http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/Config.html#constructor-property
    }
});

awsQueue.add({path: 'AMS.rar'});

awsQueue.process(concurrency, function (job, done) {
    debug("New Job: ", job.data);
    // job.data contains the custom data passed when the job was created
    // job.jobId contains id of this job.
    var params = {
        localFile: job.data.path,
        s3Params: {
            Bucket: 'bulltest',
            Key: job.data.path
        },
    };

    var uploader = client.uploadFile(params);

    uploader.on('error', function (err) {
        //Will pause the queue if error occurs
        console.log("Error", err);
        //exports.pauseUpload();

        done(Error(err));
    })
    .on('progress', function () {
     //   console.log("progress", uploader.progressAmount)
        var data = {
            progressAmount: uploader.progressAmount,
            progressTotal: uploader.progressTotal,
            filename: uploader.filename
        };
        job.progress(JSON.stringify(data));
    })
    .on('end', function () {
        console.log("end", uploader.filename)
        var data = {
            filename: uploader.filename
        };
        done(null, data);
    });
});

awsQueue.on('ready', function () {
    // Queue ready for job
    // All Redis connections are done
    debug('ready');
})
    .on('error', function (error) {
        // Error
        debug(error);
    })
    .on('active', function (job, jobPromise) {
        // Job started
        // You can use jobPromise.cancel() to abort this job.
        debug('active', job.data.path);
    })
    .on('stalled', function (job) {
        // The job was considered stalled (i.e. its lock was not renewed in LOCK_RENEW_TIME).
        // Useful for debugging job workers that crash or pause the event loop.
        debug('job has been stalled');
    })
    .on('progress', function (job, progress) {
        // Job progress updated!
        debug('Progress: ', progress);
    })
    .on('completed', function (job, result) {
        // Job completed with output result!
        debug('result: ', result);
    })
    .on('failed', function (job, err) {
        // Job failed with reason err!
        debug('failed', job.data);
    })
    .on('paused', function () {
        // The queue has been paused
    })
    .on('resumed', function (job) {
        // The queue has been resumed
    })
    .on('cleaned', function (jobs, type) {
        //jobs is an array of cleaned jobs
        //type is the type of job cleaned
        //see clean for details
        debug(jobs);
        debug(type);
    });


